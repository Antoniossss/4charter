###The task

A retailer offers a rewards program to its customers, awarding points based on each recorded purchase.

A customer receives 2 points for every dollar spent over $100 in each transaction, plus 1 point for every dollar spent over $50 in each transaction

(e.g. a $120 purchase = 2x$20 + 1x$50 = 90 points).



Given a record of every transaction during a three month period, calculate the reward points earned for each customer per month and total.

###### as I understand it (which somehow took me a moment to understand) 
* x <= 50 no points
* x > 50 && x <= 100 = 1points per dollar (max 50)
* x > 100 = 2 points per each dollar (excluding 50-100 pointing range, which was not entirely clear) 

#### Requirements 
In order to test build and run application you must have

* JDK 8+
* Maven (LTS)
* NodeJS (LTS)

#### How to build app

* 


